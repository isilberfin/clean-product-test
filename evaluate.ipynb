{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# set the paths for the input image and the trained model\n",
    "input_image_path = 'path/to/image.jpg'\n",
    "model_path = 'path/to/model.h5'\n",
    "\n",
    "# set the window size and stride\n",
    "window_size = (500, 500)\n",
    "stride = (window_size[0] // 2, window_size[1] // 2)\n",
    "\n",
    "# set the threshold for letter probability\n",
    "threshold = 0.5\n",
    "\n",
    "# load the trained model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# load the input image\n",
    "input_image = cv2.imread(input_image_path)\n",
    "\n",
    "# get the image dimensions\n",
    "height, width, _ = input_image.shape\n",
    "\n",
    "# create a list to store the predicted letters\n",
    "predicted_letters = []\n",
    "\n",
    "# loop over all the windows in the image\n",
    "for y in range(0, height - window_size[1] + 1, stride[1]):\n",
    "    for x in range(0, width - window_size[0] + 1, stride[0]):\n",
    "        # extract the window from the image\n",
    "        window = input_image[y:y+window_size[1], x:x+window_size[0]]\n",
    "\n",
    "        # preprocess the window for the model\n",
    "        window = cv2.resize(window, (500, 500))\n",
    "        window = cv2.cvtColor(window, cv2.COLOR_BGR2RGB)\n",
    "        window = window.astype(np.float32) / 255.0\n",
    "        window = np.expand_dims(window, axis=0)\n",
    "\n",
    "        # make a prediction for the window\n",
    "        predictions = model.predict(window)\n",
    "\n",
    "        # get the letter with the highest probability\n",
    "        max_prob_index = np.argmax(predictions)\n",
    "        max_prob = predictions[0, max_prob_index]\n",
    "\n",
    "        # add the letter to the predicted letters list if its probability is above the threshold\n",
    "        if max_prob > threshold:\n",
    "            letter = letter_box[max_prob_index]\n",
    "            letter_x = x + window_size[0] // 2\n",
    "            letter_y = y + window_size[1] // 2\n",
    "            predicted_letters.append((letter, letter_x, letter_y, max_prob))\n",
    "\n",
    "# cluster the predicted letters\n",
    "positions = np.array([(x, y) for _, x, y, _ in predicted_letters])\n",
    "weights = np.array([prob for _, _, _, prob in predicted_letters])\n",
    "clustering = DBSCAN(eps=window_size[0] // 2, min_samples=2).fit(positions, sample_weight=weights)\n",
    "labels = clustering.labels_\n",
    "\n",
    "# group the predicted letters by cluster\n",
    "letter_clusters = {}\n",
    "for i, label in enumerate(labels):\n",
    "    if label == -1:\n",
    "        continue\n",
    "    if label not in letter_clusters:\n",
    "        letter_clusters[label] = []\n",
    "    letter_clusters[label].append(predicted_letters[i])\n",
    "\n",
    "# output the final predictions\n",
    "for cluster in letter_clusters.values():\n",
    "    letters = [letter for letter, _, _, _ in cluster]\n",
    "    probs = [prob for _, _, _, prob in cluster]\n",
    "    x = sum([x * prob for _, x, _, prob in cluster]) / sum(probs)\n",
    "    y = sum([y * prob for _, _, y, prob in cluster]) / sum(probs)\n",
    "    print('Letters:', letters)\n",
    "    print('Position:', (x, y))\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
